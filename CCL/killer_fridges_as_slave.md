# Cos'è la robotica?
La robotica è l'area dell'IA che riguarda l'uso di robot, cioè, secondo George A. Bekey, macchine che "sentono, pensano e agiscono".

"Questo campo è interdisciplinare per eccellenza, coinvolgendo non solo l'intelligenza artificiale e l'informatica, ma anche cibernetica, 
fisica, matematica, meccanica, elettronica, neuroscienze, biologia e scienze umane".

# I robot possono essere assassini?

La prima metafora dei robot come assassini è illustrata dagli avvertimenti di Asimov nei suoi romanzi e dalla prima legge della robotica, secondo la quale nessun essere umano può essere ferito dai robot (ciò che accade spesso nelle storie di Asimov). Una delle aree più rilevanti e sviluppate della robotica di oggi, dopo tutto, riguarda applicazioni militari come armi intelligenti, soldati robot e persino soldati sovrumani con sistemi di sensori, dispositivi di realtà aumentata o esoscheletri.

La seconda immagine è quella dei 'frigoriferi'. Gli studiosi usano spesso questa metafora per prevenire alcune esagerazioni nel dibattito attuale, come i robot assassini e altri agenti artificiali che superano in astuzia gli umani, così che noi, come specie, ci troveremmo presto di fronte all'estinzione poiché i robot intelligenti ci sostituiranno come prossimo passo nell'evoluzione (Moravec 1999). 

Contro questa sorta di tecno-determinismo e altre peculazioni fantascientifiche, la metafora del frigorifero propone un quadro più sobrio dei robot e della loro peculiare autonomia: 
> "Possono affrontare con successo i loro compiti, anche se hanno l'intelligenza di un frigorifero (Floridi 2007).

# tre leggi della robotica

"roviamo l'immagine dei robot come "schiavi". Analogamente al modo in cui gli schiavi erano disciplinati dall'antica legge romana, possiamo considerare i robot come agenti autonomi che sono comunque solo 'cose', eventualmente prive di diritti e doveri. Questo terzo parallelismo fa luce su una nuova forma di agenzia, in quanto, "come uno schiavo, [il robot] è in grado di prendere decisioni che influenzeranno i diritti (e, nel diritto successivo, le responsabilità) del suo padrone. 
Facilitando le transazioni commerciali, gli agenti autonomi hanno la capacità di aumentare l'efficienza del mercato. 
> Come uno schiavo, un agente autonomo è capace di fare danni (Katz 2008).

# Una prospettiva giuridica

Forse è troppo presto per ipotizzare una responsabilità personale dei robot negli affari penali, come sia nell'esempio di responsabilità per reati sessuali proposto da Fernando Barrio (2008), sia nelle ipotesi del ''robot cleptomane'' e del ''picciotto roboto'' illustrate da Reynolds e Ishikawa (2007).

Tuttavia, è giunto il momento di riconoscere seriamente che il comportamento dei robot dovrebbe essere considerato giuridicamente come una nuova fonte di responsabilità personale per gli atti altrui (ad esempio, il diritto di torto e la responsabilità vicaria nella tradizione della common law e la sua controparte nel diritto civile, cioè la 'responsabilità oggettiva' o responsabilità senza colpa).

Le seguenti precisazioni riguardano tre questioni:

Innanzitutto, analizzo come i robot abbiano stimolato il dibattito degli studiosi su alcuni campi fondamentali della giurisprudenza e della teoria giuridica. Più in particolare, considero il caso dell'ermeneutica e le suddette leggi della robotica nell'opera di Isaac Asimov

In secondo luogo, illustro lo stato attuale dell'arte della scienza giuridica: particolare attenzione è rivolta alle nozioni di agenzia e di responsabilità civile (in contrapposizione a quella penale).

In terzo luogo, spiego le ragioni per cui penso che dovremmo aggiungere una nuova forma di responsabilità legale per il comportamento degli altri: I robot, proprio come gli schiavi, sono considerati 'cose' con un'autonomia significativa e, forse, alcuni doveri specifici.

Analogie giuridiche:
- Da un lato, il ruolo di alcune metafore è quello di afferrare una serie di questioni giuridiche come se i robot fossero assassini, schiavi, e simili, al fine di rispettare il dogma del diritto civile come un sistema autoreferenziale in cui l'analogia può riempire le sue lacune normative. 
- D'altra parte, le metafore possono essere utilizzate per chiarire alcuni quesiti tipici riguardanti il campo a cui gli studiosi di solito si riferiscono come giurisprudenza (nella tradizione del common law) o come 'teoria generale del diritto' (nella tradizione del civil law). Per esempio, assumendo le leggi della robotica di Asimov, è possibile illustrare alcuni temi giuridici classici che, secondo Herbert Hart (1961).

Comincio con la citazione delle leggi di Asimov in Runaround (1942):
1. Un robot non può nuocere a un essere umano o, attraverso l'inazione, permettere che un essere umano venga a nuocere.
2. Un robot deve obbedire agli ordini impartitigli dagli esseri umani, tranne quando tali ordini sarebbero in conflitto con la Prima Legge.
3. Un robot deve proteggere la propria esistenza, purché tale protezione non sia in conflitto con la Prima o la Seconda Legge.


In Robots and Empire (1985), Asimov aggiunse una quarta legge, la legge "Zeroth":
0. Un robot non può ferire l'umanità o, attraverso l'inazione, permettere che l'umanità si faccia male".

Il legame tra le leggi della robotica e la legge naturale ci suggerisce di riconsiderare il significato dei comandi legali, poiché la legge naturale doveva guidare le nostre azioni nello stesso modo in cui le leggi della robotica dirigerebbero il comportamento dei robot. In entrambi i casi, la legge può essere vista come un imperativo oggettivo la cui violazione implicherebbe una violazione della natura dell'agente.

La Prima Legge della Robotica dovrebbe essere integrata da una meta-legge, che determina che un robot non può agire se le sue azioni non sono soggette alle Leggi della Robotica.

Una seconda sezione è aggiunta alla seconda legge in quanto "un robot deve obbedire agli ordini impartitigli da robot sovraordinati". Inoltre, una nuova prima sezione dovrebbe essere inserita nella terza legge, e così via.


I problemi etici che coinvolgono la legge dovrebbero essere aggiunti alla lista dei possibili parallelismi tra le leggi della robotica e la teoria giuridica
Possiamo ulteriormente sollevare questioni sul libero arbitrio come base della responsabilità dei signori, questioni di paternalismo robotico e obiettori di coscienza, fino al contenuto minimo della legge naturale, cioè "l'insieme minimo di principi che, in quanto razionalmente necessari dati alcuni "truismi" fondamentali sulla natura umana e la situazione umana - per la garanzia di scopi condivisi da tutte le società umane sopravvissibili - possono essere definiti legge naturale. (Hart 1961).


Tre domande:

- In primo luogo, la proprietà specifica delle leggi della robotica, cioè la loro natura astratta e generale, comporta il difficile compito di applicare queste leggi ad un determinato contesto: Le circostanze del contesto influenzano il modo in cui interpretiamo quelle regole generali?
- La vaghezza del linguaggio ordinario, come nel caso di termini cruciali come "danno" o "ordine", mette a rischio la possibilità di assicurare l'osservanza meccanica delle regole: Sarebbe fattibile sviluppare modelli computabili in modo da comprendere non solo le norme e i concetti giuridici ma anche gli agenti giuridici?
- Infine, una corretta comprensione del diritto è caratterizzata da diverse serie di criteri di interpretazione delle leggi del sistema".


Come esemplificato dal lavoro di Asimov, i robot adottavano una sorta di lettura letterale nei suoi primi romanzi: Solo i robot estremamente più sofisticati delle storie successive cominciarono a impiegare tecniche ermeneutiche complesse come interpretazioni rigorose o estensive delle leggi, letture evolutive e teleologiche dei testi, e così via.

Ovviamente, dato l'approccio troppo articolato dei teorici del diritto, il rischio finale (e fatale) di tutte queste analisi astratte è di finire nella paralisi. 

In qualche modo, ciò che gli studiosi discutono incessantemente in termini di configurazioni meccaniche contro configurazioni olistiche del sistema, lettura letterale contro lettura contestuale dei testi, comprensione analitica contro comprensione sistematica delle norme, può portare all'esito di alcune trame di Asimov, cioè all'deadlock dei cervelli positronici dei suoi robot.

# La responsabilità morale del robot

Dovremmo ammettere la responsabilità morale dei robot negli omicidi?.

Estendendo la classe degli agenti moralmente responsabili in modo da includere l'agenzia artificiale dei robot, non abbiamo bisogno di ammettere né la loro responsabilità morale né la loro responsabilità penale. Come nei casi delle azioni dei bambini o del comportamento degli animali, la ragione si impernia sulla necessità di differenziare la fonte delle azioni morali rilevanti dalla valutazione degli agenti come moralmente responsabili di un certo comportamento

Questo è il motivo per cui Floridi e Sanders, che riconoscono la responsabilità morale degli agenti artificiali, ammettono prontamente ''che sarebbe ridicolo lodare o biasimare un agente artificiale per il suo comportamento o caricarlo di un'accusa morale''. (op. cit., 17)".

## responsabilità morale e responsabilità legale

Possiamo affrontare la domanda di Daniel Dennett su ''di chi è la colpa, quando HAL uccide? (1997, 351), dicendo ''che HAL è responsabile - anche se non lo è - se soddisfa le condizioni che definiscono l'agentività''. (Floridi e Sanders 2005, 26)".

"Secondo lo stato attuale dell'arte del diritto penale, sarebbe inutile discutere davanti a un giudice se un robot debba essere considerato o meno un "assassino", un "rapinatore" e così via.

Anche se assumiamo che una sorta di responsabilità morale sia un requisito necessario per la responsabilità legale, la prima non rappresenta la condizione sufficiente della seconda, perché gli intervistati dovrebbero essere soggetti all'ordinario processo di valutazione morale al fine di determinare se sono colpevoli o meno in nome della legge


Altrimenti, confondendo responsabilità morale e responsabilità legale, saremmo costretti a tornare ai giorni in cui i processi penali erano comunemente eseguiti contro animali e persino cose senza vita (Ewald 1995)".

Possiamo mettere in conto che i robot paghino il loro debito verso la società? 
	
Possiamo correggere il loro carattere morale in modo che i robot capiscano perché non devono ripetere un male

Possiamo punirli in modo da dissuadere gli esseri umani dal commettere simili torti?