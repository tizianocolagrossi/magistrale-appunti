
"C'è una serie di ragioni etiche e tecniche per cui rendere automatica la protezione legale è problematico. Per quanto riguarda le ragioni etiche, si consideri come specifiche scelte progettuali possano risultare in conflitti tra valori e, viceversa, i conflitti tra valori possano avere un impatto sulle caratteristiche del design: abbiamo la prova che "alcuni artefatti tecnici portano direttamente e sistematicamente alla realizzazione, o alla soppressione, di particolari configurazioni di valori sociali, etici e politici".
"Nel caso della protezione dei dati, introdotta sopra nella sezione precedente, contemplate le diverse caratteristiche che la privacy by design acquisisce, una volta che la protezione dei dati è colta in termini di diritti di proprietà o di dignità umana, di controllo totale o di integrità contestuale, di accesso ristretto o di controllo limitato sulle informazioni. In definitiva, un artefatto deve essere progettato secondo il tradizionale modello europeo di opt-in per gli utenti dei sistemi di comunicazione elettronica o, viceversa, secondo l'approccio americano op tout?".
"Inoltre, riflettete sul sistema informativo degli ospedali menzionato sopra nella sezione II.i: dovremmo privilegiare l'efficacia e l'affidabilità di quel sistema informativo nel tenere separati i nomi dei pazienti dai dati sui trattamenti medici o sullo stato di salute? Ma come la mettiamo con gli utenti, compresi i medici, che potrebbero trovare tale meccanismo troppo oneroso?".


"Per quanto riguarda le ragioni legali contro questo tipo di politica di progettazione, lo sviluppo e l'uso dell'automazione legale può limitare gravemente l'autonomia sia collettiva che individuale. I principi di base dello stato di diritto sarebbero a rischio, una volta che il comportamento delle persone è unilateralmente determinato sulla base della tecnologia".
"In primo luogo, c'è la minaccia di aggiornare le forme tradizionali di paternalismo attraverso gli strumenti normativi della tecnologia, perché più le scelte personali sono spazzate via dall'automazione giuridica, più grande è il pericolo di modellare la condotta sociale attraverso il design". 
"In secondo luogo, l'attenzione va posta sulle questioni dell'applicazione della legge e delle sue eccezioni: ciò che è in pericolo qui è "l'under standing pubblico della legge con la sua applicazione che elimina un'interfaccia auseful tra i termini della legge e la sua applicazione".


"In terzo luogo, i riassetti del sistema di applicazione della legge si intrecciano con le ridistribuzioni del potere e il ruolo delle istituzioni politiche pertinenti con le loro decisioni". 
"Come avverte Lawrence Lessig, la minaccia è che "i controlli sull'accesso ai contenuti non saranno controlli ratificati dai tribunali; i controlli sull'accesso ai contenuti saranno controlli che lo sono".


"Infine, le difficoltà tecniche di raggiungere un tale controllo totale attraverso la progettazione dovrebbero essere menzionate". 
"I dubbi sono espressi da "un ricco corpo di studi riguardanti la teoria e la pratica della regolamentazione basata su regole 'tradizionali' [che] testimonia l'impossibilità di progettare standard normativi sotto forma di norme giuridiche che colpiranno il loro obiettivo con perfetta precisione".


"Come sottolineato sopra nella sezione II.1, c'è effettivamente la difficoltà tecnica di applicare a una macchina concetti tradizionalmente impiegati dai giuristi, attraverso la formalizzazione di norme, diritti o doveri: le garanzie giuridiche presentano infatti nozioni profondamente 
"Nelle parole di Bert-Jaap Koops e Ronald Leenes, "l'idea di codificare le norme giuridiche all'inizio dei sistemi di elaborazione delle informazioni è in contrasto con la natura dinamica e fluida di molte norme giuridiche, che hanno bisogno di uno spazio di respiro che non è tipicamente qualcosa che può essere incorporato nel software".


"In termini più generali, l'automazione giuridica incide profondamente sia sui requisiti che sulle funzioni della legge, cioè su ciò che la legge dovrebbe essere (requisiti) e su ciò che è chiamata a fare (funzioni)". 
"Prima di tutto, l'automazione giuridica ha un impatto sulla visione tradizionale della legge come un mezzo per il controllo sociale attraverso un insieme di regole applicate attraverso la minaccia di sanzioni fisiche: "se A, allora B". 
"Rendendo automatica l'applicazione della legge, la legge viene convertita in un insieme di effetti (B) che seguono automaticamente istruzioni tecniche (A), piuttosto che sanzioni (B) che dovrebbero seguire i termini e le condizioni della responsabilità legale (A), cioè ciò che è, piuttosto che ciò che dovrebbe essere".


"Il contro dell'automazione giuridica può essere approfondito con un caso particolare riguardante l'uso di sistemi di filtraggio su internet (sezione 111.1)". 
"Questa presa di posizione ci permette di capire perché, almeno nell'UE, alcuni di questi sistemi di filtraggio dovrebbero essere considerati illegali (sezione 111.2); e tuttavia, anche dopo la sentenza della Corte di giustizia del 2012, tale uso è destinato a rimanere una questione aperta (sezione 111.3)". 
"Dopo questa analisi, saremo pronti ad esaminare la governance dell'automazione legale (sezione IV)". 


"Un vivace dibattito su quale ruolo debbano avere gli intermediari internet, o fornitori di servizi ("ISP"), per garantire la sicurezza online e la protezione dei diritti individuali, si è svolto in Europa negli ultimi anni".
"Le opinioni nel dibattito possono essere concepite come appartenenti alle estremità di uno spettro che riguarda le autorità pubbliche che richiedono alle aziende private di salvaguardare la sicurezza online, ad esempio gli ISP come sceriffi della rete e, viceversa, le aziende private che fanno pressione sulle autorità pubbliche per far rispettare i propri diritti e interessi attraverso l'uso di sistemi di filtraggio su Internet".


"Ad un estremo, la sicurezza ha la meglio sui diritti civili attraverso l'uso di questi sistemi di filtraggio, perché quest'ultimo renderebbe impossibile qualsiasi equilibrio tra l'obiettivo di garantire la sicurezza online e la protezione di alcuni diritti fondamentali, come la protezione dei dati, la libertà di parola e di informazione, o la libertà di condurre un'attività". 
"All'altra estremità dello spettro, ci sono limiti costituzionali all'uso di tali sistemi di filtraggio per proteggere alcuni dei diritti fondamentali sopra menzionati. Un caso discusso davanti alla Corte di giustizia dell'UE, cioè Netlog (C-36o/lo), sembra istruttivo per illustrare le estremità di questo spettro".


"L'attore in Net log era una società di gestione, SABAM, che rappresenta autori, compositori ed editori di opere musicali in Belgio".
"Come tale, la SABAM è responsabile di autorizzare l'uso da parte di terzi di opere protette dal diritto d'autore di questi autori, compositori ed editori". 


"Di conseguenza, il giudice nazionale avrebbe dovuto emettere un'ingiunzione contro il social network imponendo a quest'ultimo di installare un sistema che, nella formulazione della Corte di giustizia dell'UE, dovrebbe filtrare: 

a. "Le informazioni che sono memorizzate sui suoi server dagli utenti del suo servizio; 
b. Che si applica indiscriminatamente a tutti questi utenti; 
c. Come misura preventiva; 
d. Esclusivamente a sue spese; ed e. Per una durata illimitata"; 


"che è in grado di identificare i file elettronici contenenti un'opera musicale, cinematografica o audiovisiva rispetto alla quale il richiedente l'ingiunzione sostiene di essere titolare di diritti di proprietà intellettuale" (C-36o/io)". 
"Conformemente al meccanismo della pronuncia pregiudiziale, il Tribunale di primo grado di Bruxelles ha presentato una domanda di pronuncia pregiudiziale alla Corte di giustizia dell'Unione europea a Lussemburgo, al fine di determinare i diritti e i doveri di trattamento delle informazioni memorizzate sulle piattaforme di rete sociale online, e di sapere se l'introduzione di un sistema di filtraggio di tali informazioni e di prevenzione della messa a disposizione di file che violano il diritto d'autore è legale nell'Unione europea"


"Inoltre, il tribunale belga ha chiesto se esiste un obbligo generale di monitorare le informazioni memorizzate. Il 16 febbraio 2012, i giudici dell'UE hanno emesso il loro verdetto sulla questione se l'uso di tecnologie auto-applicative, come il sistema di filtraggio discusso in Net log, è precluso dalla legge dell'UE". 


"Ci sono due ragioni per cui la Corte di Lussemburgo ha stabilito che il sistema di filtraggio discusso in Net log era precluso dalle direttive UE sulla protezione dei dati (1 9 9 5/46/CE), il commercio elettronico (2000/ 31/CE), il diritto d'autore (2001/2 9 /CE), e la proprietà intellettuale (2004/48/CE), così come la libertà di ricevere o impartire informazioni, secondo gli articoli 8 e 11 della Carta dei diritti fondamentali UE. Questi motivi si basano su una premessa. Citando la sua giurisprudenza (C-27 5 /o6, cioè Promusicae), la Corte afferma che nessuno dei diritti di proprietà intellettuale è "inviolabile" o "assoluto", ma piuttosto deve essere bilanciato con la protezione di altri diritti fondamentali (C-360/1o, %% 42-43)".


"Pertanto, da un lato, "una siffatta ingiunzione [che impone l'installazione del sistema di filtraggio controverso] si tradurrebbe in una grave violazione della libertà di impresa del prestatore di servizi di hosting, poiché imporrebbe a quest'ultimo di installare a proprie spese un sistema informatico complicato, costoso e permanente, il che sarebbe altresì contrario alle condizioni previste dall'articolo 3, paragrafo 1, della direttiva 2004/48, il quale richiede che le misure volte ad assicurare il rispetto dei diritti di proprietà intellettuale non siano inutilmente complicate o costose" (op. cit., % 46)". 


"D'altra parte, secondo la Corte, questo campione di automazione giuridica dovrebbe essere considerato illegittimo perché indiscriminato". 
"L'installazione di un tale sistema di filtraggio non comporterebbe soltanto l'identificazione, l'analisi sistematica e il trattamento delle informazioni legate ai profili creati sul social network dai suoi utenti, e quindi l'implicazione delle modalità di protezione dei dati personali". 
"Inoltre, tale ingiunzione [di installare il sistema di filtraggio] potrebbe potenzialmente compromettere la libertà di informazione, poiché tale sistema potrebbe non distinguere adeguatamente tra contenuti illeciti e contenuti leciti, con la conseguenza che la sua introduzione potrebbe portare al blocco delle comunicazioni lecite" (op. cit., % 50)".


"Di conseguenza, non solo il tipo di automazione giuridica, in gioco in Net log, deve essere considerato illegittimo, al fine di proteggere diritti fondamentali come la libertà di ricevere o impartire informazioni, o la protezione dei dati personali, ma è degno di nota che nessun bilanciamento era necessario nel caso". 
"Nella formulazione della Corte, il diritto comunitario "deve essere interpretato nel senso che impedisce a un giudice nazionale di emettere un'ingiunzione contro un fornitore di servizi di hosting che gli impone di installare un sistema di filtraggio".






"Nella formulazione della Corte, il diritto dell'UE "deve essere interpretato nel senso che impedisce a un giudice nazionale di emettere un'ingiunzione contro un fornitore di servizi di hosting che gli impone di installare un sistema di filtraggio".
"Più recentemente, l'8 aprile 2014, un verdetto simile è stato emesso in relazione alla direttiva UE del 2006 sulla conservazione dei dati (cause riunite C-293/12 e C- 5 94/12)".


"I giudici di Lussemburgo hanno dichiarato quest'ultima invalida, perché la D-2006/24/CE ha violato il principio di proporzionalità colpendo "tutte le persone e tutti i mezzi di comunicazione elettronica, nonché tutti i dati sul traffico senza alcuna differenziazione, limitazione o eccezione"
"essendo fatta alla luce dell'obiettivo della lotta contro le forme gravi di criminalità" (op. cit., % 56)".


"Inoltre, nessun "criterio oggettivo" è stato previsto nella direttiva per determinare chi può accedere ai dati conservati conformemente alla direttiva 24 del 2006 e farne uso e "ciò che è strettamente necessario alla luce dell'obiettivo perseguito" (op. cit., % 62)". 
"Come si è verificato nel caso Netlog, non è stato necessario alcun bilanciamento
per dichiarare invalide tali disposizioni. 
Tuttavia, trattando
la legittimità di quanto lontano le norme di automazione giuridica
possono spingersi, non dovremmo saltare alle conclusioni".


"Mentre è possibile rimuginare su sistemi di filtraggio a buon mercato che non finiscono "in una grave violazione della libertà del fornitore di servizi di hosting", o su tecnologie più intelligenti e auto-applicative che distinguono adeguatamente il contenuto illegale dalle comunicazioni legali delle persone, dove dovremmo legalmente tracciare la linea tra i pro e i contro dell'automazione legale appare ancora più difficile. La prossima sezione mira a spiegare perché questo è il caso".


"Non è ancora chiaro quale tipo di automazione legale sarebbe alla fine legittimo nel diritto dell'UE. Due esempi sono fruttuosi per illustrare il punto. In primo luogo, alcune disposizioni controverse del Digital Economy Act (DEA) britannico del 2010 ci riportano alle incertezze e ai dilemmi che finiscono con la sentenza preliminare nel caso Netlog". 
"La DEA stabilisce un "codice di obblighi iniziali" che dovrebbe imporre agli ISP il dovere di notificare agli abbonati le segnalazioni di violazione del copyright ricevute dai proprietari dei diritti d'autore, e di fornire liste di violazione dei diritti d'autore ai proprietari dei diritti d'autore, oltre agli "obblighi tecnici", alcuni dei quali includono un "codice di obblighi tecnici". 
"Alcuni ISP, come British Telecom, hanno sostenuto che tali disposizioni sono illegittime secondo il diritto comunitario".


"Tuttavia, due tribunali britannici hanno avallato l'opinione di alcuni potenti titolari di diritti di copia e hanno semplicemente ignorato la giurisprudenza della Corte di giustizia dell'UE. Nella formulazione della Corte d'appello di Londra, il 6 marzo 2012, "una certa quantità di energia è stata spesa prima di noi sulla recente sentenza della Corte di giustizia in Scarlet... che riguardava la compatibilità con la direttiva sulla privacy e le comunicazioni elettroniche e altre direttive di un'ingiunzione del tribunale contro un ISP che gli imponeva di installare un sistema di filtraggio delle comunicazioni elettroniche al fine di identificare e bloccare il trasferimento di file che violavano il copyright".


"Sia l'avvocato generale che la Corte hanno fatto riferimento a Promusicae, in termini che a mio parere non gettano una grande luce su quella sentenza; ma non vedo nulla nel caso per sostenere la portata limitata che i ricorrenti cercano di dare alla sentenza in Promusicae" (CI/2011/1437, n. 82)".
"In secondo luogo, la Corte di Giustizia UE ha cambiato idea con la sentenza in Google v. AEPD, cioè il famoso caso sul diritto all'oblio del 13 maggio 2014 (C-131/12)".


"Qui, per motivi dichiaratamente politici, i giudici di Lussemburgo hanno stabilito che i motori di ricerca, come quello di Google, devono essere concepiti come "responsabili del trattamento dei dati" (op. cit., %% 33 e 34), annullando così quanto era stato dichiarato nel caso Google v. Louis Vuitton del 23 marzo 2010". 
"In quest'ultima occasione, l'opinione era che la responsabilità dei fornitori di servizi di referenziamento online dipende in ultima analisi "dalle condizioni effettive in cui il servizio viene fornito".




"In altre parole, secondo i giudici di Lussemburgo, bisognava determinare, almeno fino al 13 maggio 2014, "se il ruolo svolto da tale fornitore di servizi è neutro, nel senso che il suo comportamento è meramente tecnico, automatico e passivo, il che indica una mancanza di conoscenza o di controllo dei dati che conserva" (% 114 della decisione)". 
"Alcuni ritengono che, ribaltando questa idea e sostenendo che gli algoritmi dei motori di ricerca non sono più neutrali, la Corte ha anticipato ciò che la Commissione ha proposto con l'articolo 17 del nuovo regolamento UE sulla protezione dei dati dal gennaio 2012, cioè una nuova serie di doveri e obblighi per gli ISP in nome del diritto all'oblio". 
"Eppure, nel novembre 2013 e successivamente, nel marzo 2014, il Parlamento Ue ha approvato una serie di emendamenti che ridisegnano questo insieme di regole, tanto che persino il riferimento al diritto all'oblio è stato messo tra parentesi nel nuovo testo".


"Alla luce di questi esempi, ciò che appare chiaro è l'urgenza di una presa di posizione normativa con cui affrontare le sfide di rendere automatico il ragionamento giuridico e l'applicazione delle norme". 
"Questo richiede intelligenza e, inoltre, non può essere direttamente subordinato all'automazione giuridica". 
"Piuttosto, la posta in gioco riguarda decisioni critiche nei confronti della salvaguardia dei diritti giuridici fondamentali, tanto quanto le scelte di dipendenza tecnologica e di delega, che devono accertare il buon mix tra automazione giuridica e deliberazione pubblica. Approfondiamo questo complesso insieme di questioni nella parte finale dell'articolo".


"La delega di decisioni a sistemi automatizzati deve affrontare una duplice grandezza di complessità". 
"Insieme all'obiettivo di incorporare i vincoli normativi nella tecnologia, l'attenzione dovrebbe essere rivolta all'interazione tra diritto e tecnologia e, inoltre, all'intento del diritto di governare il processo di innovazione tecnologica in modo tale che la regolamentazione giuridica non debba né ostacolare l'avanzamento della tecnologia, né richiedere una revisione troppo frequente per affrontare un tale EJRR |2016progresso". 
"Quest'ultima prospettiva sulle finalità regolative del diritto non deve essere confusa con la tecno-regolamentazione, cioè come gli attuali progressi della tecnologia hanno obbligato i legislatori e i politici a forgiare modi più sofisticati di pensare all'applicazione del diritto".


"La delega di decisioni a sistemi automatizzati deve affrontare una duplice grandezza di complessità". 
"Insieme all'obiettivo di incorporare i vincoli normativi nella tecnologia, l'attenzione dovrebbe essere rivolta all'interazione tra legge e tecnologia e, inoltre, all'intento della legge di governare il processo di innovazione tecnologica in modo tale che la regolamentazione giuridica non debba né ostacolare l'avanzamento della tecnologia, né richiedere una revisione troppo frequente per affrontare tale EJRR |2016progresso". 
"Quest'ultima prospettiva sulle finalità regolative della legge non deve essere confusa con la tecno-regolamentazione, cioè con il modo in cui gli attuali progressi della tecnologia hanno obbligato i legislatori e i policy maker a forgiare modi più sofisticati di pensare all'applicazione della legge".


"Nel caso della legge che regola l'innovazione tecnologica, cioè la legge concepita come una "meta-tecnologia "2 0 , l'attenzione si concentra sui diversi scopi normativi che la legge può avere, compreso quello che gli studiosi spesso doppiano come la "neutralità tecnologica" della legge. Per esempio, secondo Chris Reed 2 1, dovremmo distinguere tra (a) l'indifferenza tecnologica, cioè norme giuridiche che si applicano in modo identico, qualunque sia la tecnologia, come il diritto di autorizzare la comunicazione di un'opera al pubblico nel campo del diritto d'autore; 
(b) la neutralità dell'implementazione, per cui le regolamentazioni sono per definizione specifiche a quella tecnologia e tuttavia non favoriscono una o più delle sue possibili implementazioni, per esempio la firma dei documenti elettronici; e, 
(c) neutralità potenziale della legge che stabilisce un particolare attributo di una tecnologia, sebbene i legislatori possano redigere il requisito legale in modo che anche le implementazioni non conformi possano essere modificate per diventare conformi".

"In alternativa, Bert-Jaap Koops ha proposto di distinguere quattro scopi legislativi principali, quali: 
(a) il raggiungimento di particolari effetti, ad esempio impedire che si verifichino comportamenti generatori di danni, o diminuirne l'impatto, attraverso l'automazione legale;
(b) l'equivalenza funzionale tra attività online e offline, ad esempio le misure di sicurezza per gli impianti di impianti atomici e i loro sistemi informatici; 
(c) non discriminazione tra tecnologie con effetti equivalenti; e, 
(d) l'impermeabilità al futuro della legge che dovrebbe essere compatibile con il progresso della tecnologia, in modo da non essere spesso rivista per tenere il passo di tale innovazione".


"I modi diversi e persino opposti in cui possiamo cogliere le finalità normative del diritto come metatecnologia consigliano di ampliare la nostra visione. 
Proponiamo quattro passi di analisi. In primo luogo, un approccio meta-normativo al campo dell'automazione giuridica dovrebbe permetterci di determinare se, e in che misura, i legislatori non devono (o non possono) delegare decisioni a sistemi automatizzati".


In secondo luogo, ci si dovrebbe concentrare sull'impatto della tecnologia sui formalismi del diritto, e come quest'ultimo compete con ulteriori sistemi normativi". 
"In terzo luogo, dobbiamo prestare attenzione ai principi e ai valori che sono in gioco con la delega delle decisioni ai sistemi automatizzati, vale a dire la dimensione istituzionale del diritto con questioni di interpretazione e deliberazione". 


"Quarto, la distinzione tra decisioni automatiche e non automatiche del diritto, e la loro legittimità, può comportare una classe di problemi giuridici, cioè i casi difficili del diritto, dove il disaccordo può ruotare intorno alla semantica, o al ragionamento giuridico, o al ruolo e alla logica dei principi nel sistema. 
Ognuno di questi temi è approfondito nelle quattro parti di questa sezione sui limiti dell'automazione giuridica (IV1); i sistemi normativi concorrenti (IV.2); la dimensione istituzionale del diritto (IV 3 ); e i suoi casi difficili (IV4). Poi, i tempi saranno maturi per le conclusioni di questo articolo".






