# Big Data 

## introduzione

Negli ultimi anni è stata dedicata una notevole attenzione allo studio delle sfide legali associate ai Big Data. 
L'enfasi principale (anche nel campo della protezione dei dati, ma non solo) è stata sul ruolo e sul contenuto delle norme primarie del sistema.

Questa posizione ha perfettamente senso: 
  
pone l'attenzione sulle norme che dovrebbero governare il comportamento sociale e individuale in termini che vanno dal consenso individuale e la minimizzazione dei dati, l'accuratezza e la limitazione dello scopo, l'integrità e la riservatezza, ai principi di pienezza della legge, equità e trasparenza, come sancito dall'articolo 5 del regolamento generale sulla protezione dei dati dell'UE (GDPR). 

Tuttavia, sostengo qui che è il momento di ampliare la nostra prospettiva per includere non solo le leggi della governance dell'UE, ma anche per considerare il ruolo giocato dalle regole secondarie della legge. 

Allo stesso tempo, dobbiamo valutare l'intento della legge nel governare il processo di innovazione tecnologica e i diversi modi in cui i comportamenti umani e sociali possono essere regolati. 

Questo articolo esamina quattro tipi di regole secondarie all'opera con (nel) GDPR e cerca di mostrare come i meccanismi e le procedure di flessibilità giuridica forniti da tali regole possano far luce sui tipi di regole primarie necessarie nel campo dei Big Data.

## start
Big Data rimane un concetto confuso. 

La prima definizione popolare di Big Data è stata fornita nel 2001 dal modello delle "tre V" di Doug Laney:

- **volume** (la dimensione e la scala dei dati),
- **velocità** (la velocità di generazione ed elaborazione dei dati)
- **varietà** (le diverse forme e la gamma dei dati analizzati). 

Più recentemente, è stata proposta una quarta "V", vale a dire:

- **veridicità** dei dati, il che significa che, ad esempio, gli errori di inserimento dell'utente, la ridondanza o la corruzione dei dati non dovrebbero influire sul loro valore complessivo.

###### positivi
Alcuni sostengono che i Big Data aprono una nuova prospettiva sulla realtà, poiché i modelli di dati possono suggerire nuovi modi di cogliere il mondo, a tal punto che potremmo persino lasciare che quei dati parlino da soli.

###### negativi
Altri si concentrano sulle sfide computazionali e umane per ordinare e analizzare tali dati, e affrontano le questioni inerenti alla dimensione e alla complessità di serie di dati sempre più grandi.


Da questo punto di vista procedurale, le sfide dei Big Data ci ricordano tre diverse serie di problemi. 

1. dobbiamo prendere in considerazione le **barriere tecniche e analitiche** **affrontate** nel **momento** stesso in cui questi **dati** sono stati **generati** ed **elaborati**. 
2. bisogna concentrarsi su casi e questioni che rivelano **aspetti etici unici e problemi teorici dei Big Data** associati alle tecnologie informatiche esistenti. Tra queste questioni, è sufficiente menzionare le questioni di **consenso, anonimizzazione, privacy e protezione dei dati**. 
3. la **complessità** dei Big Data e gli algoritmi utilizzati per analizzarli richiedono ulteriori questioni epistemologiche di oggettività e perdita di contesto. 
**Per esempio**, potremmo **perdere alcuni aspetti del fenomeno in esame riducendolo a un dato insieme di pesi e variabili**. Inoltre, le preoccupazioni epistemiche possono avere a che fare con casi di prove inconcludenti che portano ad azioni ingiustificate, o di prove imperscrutabili che portano all'opacità o di altri tipi di prove sbagliate che portano a pregiudizi. 

## nore
In termini normativi, le sfide dei Big Data possono riguardare:

- sia risultati ingiusti che portano alla **discriminazione**, 
- sia effetti trasformativi che hanno un **impatto sull'autonomia sociale e individuale**. 

Tali **sfide normative motivano una preoccupazione** finale che può essere riassunta in termini di tracciabilità, che va di pari passo con le questioni di responsabilità morale e i dilemmi dell'automazione, cioè **l'accettabilità di sostituire o aumentare il processo decisionale umano con algoritmi**.

In questo contesto, questo articolo si concentra sugli aspetti legali delle sfide normative dei Big Data, e in particolare su come il regolamento (UE) 2016/679 sulla protezione dei dati personali (il GDPR) intende governare questo aspetto cruciale delle odierne società guidate dai dati. 

Anche escludendo dall'analisi le ulteriori sfide legali dei Big Data (come le questioni della proprietà intellettuale e della proprietà dei dati, per esempio), questo livello di astrazione appare fruttuoso, poiché il GDPR mira a disciplinare  l'intero ciclo di vita delle informazioni riguardanti la produzione e il trattamento dei dati personali attraverso set e tecniche Big Data


Di conseguenza, tre aspetti dell'analisi con le loro variabili devono essere presi in considerazione. 

### sezione I
La sezione I dell'articolo esamina la pretesa normativa del diritto e i diversi modi in cui i sistemi giuridici intendono governare il processo di ricerca tecnologica e di interazione sociale con i propri mezzi. 

Qui, dovremmo **distinguere tra regole primarie e secondarie del diritto**: mentre le **prime** mirano a **governare direttamente il comportamento sociale e individuale**, le **seconde** includono **regole di riconoscimento, di aggiudicazione e di cambiamento**, cioè le regole che **permettono la creazione, la modifica e la soppressione delle regole primarie riguardanti la condotta degli individui**.

In entrambi i casi, sembra giusto affermare che **l'obiettivo del diritto di governare il processo di innovazione tecnologica non dovrebbe né ostacolarlo, né richiedere una revisione troppo frequente per gestire tale progresso**. 


### sezione II
Nella sezione II, questo tipo di equilibrio viene ulteriormente esaminato alla luce delle norme primarie del GDPR. 
Tali regole riguardano, tra l'altro, questioni di consenso individuale, il principio di minimizzazione dei dati, la pseudoanonimizzazione, e l'esenzione per la ricerca statistica che utilizza e riutilizza i dati personali. 

Per quanto riguarda le istanze di **pseudoanonimizzazione**, si consideri l'incorporazione da parte di **Apple** di tecniche di **privacy differenziale** nei suoi sforzi di raccolta dati per iOS e macOS, ad esempio, il riutilizzo dei dati sanitari ottenuti attraverso le loro app per scopi statistici. 
Come dichiarato dal Senior Vice President of Software Engineering di Apple, Craig Federighi, alla Worldwide Developers Conference del 13 giugno 2016, gli sforzi di Apple avrebbero segnato il **primo uso su larga scala delle tecniche di Aaron Roth**. Roth è il matematico che "ha letteralmente scritto il libro" su **come imparare il più possibile su un gruppo imparando il meno possibile su qualsiasi individuo in esso**. 



L'uso di tecniche di **pseudoanonimizzazione** deve essere **distinto** dall'**approccio statistico alla protezione dei dati personali**. 
Il significato della formula giuridica sugli "scopi statistici" dell'analisi dei Big Data riguarda la differenza tra un modello che, ad esempio, prevede quali clienti probabilmente diserteranno i concorrenti, in modo da offrire loro offerte migliori, e un modello che predice invece "la probabile percentuale complessiva di customer churn".

### sezione III
La discussione sull'esenzione a fini statistici porta nella sezione III  all'osservabile finale da analizzare, cioè il ruolo e la funzione delle regole secondarie della legge e, più specificamente, le regole di aggiudicazione e di cambiamento stabilite dal GDPR. 

Quattro diversi tipi di regole secondarie sono all'opera con (nel) GDPR: 
1. meccanismi di delega del potere;
2. meccanismi di coordinamento giuridico;
3. procedure di protezione preventiva dei dati;
4. procedure per rimedi giudiziari efficaci. 

Un esempio di questo tipo di meccanismo e procedura legale può essere visto nell'articolo 36 sui poteri delle autorità di controllo. 


Le disposizioni di questo articolo funzionano chiaramente come una serie di istruzioni per il comportamento dei singoli: 
"Il responsabile del trattamento [dei dati] consulta l'autorità di controllo prima del trattamento quando una valutazione d'impatto sulla protezione dei dati ai sensi dell'articolo 35 indica che il trattamento comporterebbe un rischio elevato in assenza di misure adottate dal responsabile del trattamento per attenuare il rischio". 

Eppure le autorità di controllo dell'articolo 36 sono quelle di ogni Stato membro in cui il responsabile del trattamento ha il suo stabilimento principale: si veda la norma secondaria dell'articolo 55. 

Questo riferimento incrociato implica degli sforzi di coordinamento, altrimenti il sistema rischia di rompersi. 
Da un lato, potremmo immaginare una concorrenza benefica tra i sistemi giuridici: 
una sorta di versione UE della dottrina del giudice Brandeis del federalismo sperimentale, come sostenuto in New State Ice Co. v Leibmann (285 US 262 (1932)). 
D'altra parte, alcuni avvertono che le preferenze, i valori e le paure nazionali determineranno fatalmente il futuro normativo in Europa.

Altri notano criticamente che - anche dopo che il Parlamento europeo e il Consiglio hanno approvato una serie di nuove responsabilità per i controllori dei dati e una serie di nuovi diritti per gli interessati relativi agli algoritmi decisionali e al riutilizzo dei Big Data - molte delle regole sembrano ancora vaghe e opache.

Il GDPR può essere un meccanismo sdentato o potente per proteggere gli interessati, a seconda della sua eventuale interpretazione giuridica: la formulazione del regolamento permette di fare entrambe le cose.


La conclusione dell'analisi ci riporta alla pretesa normativa del diritto e a come i sistemi giuridici mirino a governare l'innovazione tecnologica, così come la condotta individuale e sociale, con i propri mezzi (Sezione II), attraverso norme primarie (Sezione III) o secondarie (Sezione IV). 

In definitiva, l'interazione tra legge e tecnologia, e tra GDPR e Big Data deve essere colta come l'interazione tra sistemi normativi concorrenti che si contendono altri sistemi normativi, come le forze del mercato e delle norme sociali. 

Queste rivendicazioni normative possono scontrarsi o rafforzarsi a vicenda, e un sistema normativo può anche rendere superflua la rivendicazione di un altro sistema normativo. Ci sono decine di casi in cui l'intento legale di regolare il processo di innovazione tecnologica è miseramente fallito. 

Un esempio è la direttiva 46 dell'UE del 2000, la cui regolamentazione della moneta elettronica la considerava come un mero surrogato delle valute tradizionali sotto la supervisione delle autorità finanziarie nazionali


Nuove modalità di pagamento e transazioni elettroniche, come PayPal, hanno presto reso le disposizioni dell'UE inadeguate, costringendo i legislatori di Bruxelles a passare una nuova direttiva (D-200 9 /llo/CE). Un altro esempio è quello dell'articolo 8 del trattato sul copyright dell'Organizzazione Mondiale della Proprietà Intellettuale del 1996 e dell'articolo 14 del trattato gemello sulle esecuzioni e i fonogrammi. 
Vent'anni dopo la firma di questi accordi internazionali, è chiaro che le norme giuridiche non sono riuscite a far fronte al comportamento delle persone online e alle dinamiche dell'innovazione tecnologica. 

Questo articolo mostra che le **norme secondarie del GDPR giocano un ruolo cruciale nel determinare tre tipi di equilibrio**: l'equilibrio tra; 
1. sistemi di regolamentazione competitivi; 
2. gli sforzi di coordinamento e i rischi di rottura; 
3. la protezione di molteplici diritti legali; 


quest'ultima non dovrebbe ostacolare la ricerca tecnologica responsabile dei Big Data attraverso molteplici tecniche, come il machine learning, cioè gli algoritmi in grado di definire o modificare autonomamente le regole decisionali;" o la data analytics, cioè l'uso di algoritmi che danno senso a enormi flussi di dati.14 Tutto sommato, potrebbe anche essere possibile che le regole secondarie del GDPR siano interpretate in modo da rendere fattibile il triplice equilibrio.

## Su legge e tecnologia
Secondo una gloriosa tradizione filosofica che si estende almeno da Kant a Kelsen, **il diritto può essere convenientemente inteso come una tecnica**. 
Come si legge nella Teoria generale del diritto e dello Stato, "ciò che distingue l'ordine giuridico da tutti gli altri ordinamenti sociali è il fatto che esso regola il comportamento umano per mezzo di una tecnica specifica che fa perno sulla minaccia della coercizione fisica: "se A, allora B".


Ora, se la legge è una tecnica che regola un'altra tecnica, e se quest'altra tecnica è il processo di innovazione tecnologica, possiamo considerare la legge come una meta-tecnologia.
Da questo punto di vista, non ne consegue che dobbiamo accettare nessuno degli impegni ontologici di Kelsen: la posizione che questo articolo adotta sulla legge come meta-tecnologia non implica né che la legge sia semplicemente un mezzo di controllo sociale, né che non esistano altri meccanismi meta-tecnologici. 
Piuttosto, insistendo sull'intento della legge di governare il processo di innovazione tecnologica, l'attenzione dovrebbe concentrarsi sui "perché" e sui "come" della regolamentazione del comportamento umano e sociale.


Alcuni suggeriscono di distinguere **quattro obiettivi legislativi principali**: 
1. il raggiungimento di effetti particolari; 
2. l'equivalenza funzionale tra attività online e offline; 
3. non discriminazione tra tecnologie con effetti equivalenti; e, 
4. una legge a prova di futuro che non dovrebbe ostacolare il progresso della tecnologia, né richiedere una revisione troppo frequente per affrontare tale progresso.

Altri propongono di differenziare 

1. l'indifferenza tecnologica, vale a dire, norme giuridiche che si applicano in modo identico, indipendentemente dalla tecnologia; 
2. neutralità di implementazione, secondo cui le regolamentazioni sono per definizione specifiche per quella tecnologia e tuttavia non favoriscono una o più delle sue possibili implementazioni; e, 
3. neutralità potenziale della legge che stabilisce un particolare attributo di una tecnologia, sebbene i legislatori possano redigere il requisito legale in modo tale che anche le implementazioni non conformi possano essere modificate per diventare conformi.


Per quanto riguarda i modi in cui la legge può regolare sia i comportamenti umani che quelli sociali, dovremmo distinguere ulteriormente tra la tecnica tradizionale di regole che fanno perno sulla minaccia di sanzioni legali e la tecno-regolamentazione, cioè la regolamentazione legale per progettazione. 

Per esempio, l'intento della legge di regolare sia i comportamenti umani che quelli sociali nel campo della robotica può essere diviso nelle seguenti quattro categorie: 
1. la regolamentazione dei produttori umani e dei progettisti di robot e altri agenti artificiali attraverso la legge, per esempio, sia attraverso gli standard ISO o le norme di responsabilità per gli utenti di robot; 
2. la regolamentazione del comportamento degli utenti attraverso la progettazione di applicazioni di intelligenza artificiale (AI), cioè, progettandole in modo tale che non siano permesse azioni illegali degli esseri umani; 
3. la regolamentazione degli effetti legali del comportamento artificiale attraverso le norme stabilite dai legislatori, per esempio, gli effetti dei contratti e delle negoziazioni robotiche; e, 
4. la regolamentazione del comportamento artificiale attraverso il design, cioè, incorporando vincoli normativi nel design dell'applicazione. Questa differenziazione può essere completata con un ulteriore lavoro su come l'ambiente di interazione uomo-robot può essere regolato, e le sfide legali del "diritto ambientale".  Di conseguenza, si dovrebbe richiamare l'attenzione sull'insieme di valori, principi e norme che costituiscono il contesto in cui le conseguenze di tali regolamenti devono essere valutate.

Come sottolineato sopra nell'introduzione, la maggior parte degli studiosi ammetterebbe oggi che le preferenze, i valori e le paure nazionali giocheranno un ruolo cruciale nel plasmare il futuro normativo della protezione dei dati in Europa


Tuttavia, insistendo sulle diverse finalità e tecniche del diritto, possiamo reinterpretare tali rivendicazioni normative in termini binari. O riguardano le regole primarie del sistema giuridico, o hanno a che fare con i diversi tipi di regole secondarie: riconoscimento, aggiudicazione, cambiamento. Come già accennato nell'introduzione, l'obiettivo delle regole primarie è quello di governare direttamente il comportamento umano e sociale sia attraverso la tecno-regolamentazione, ad esempio, alcune varianti del principio di privacy by design, o i molteplici mezzi del diritto come meta-tecnologia, come il raggiungimento di effetti par ticolari con leggi dure (ad esempio, le regole primarie del GDPR); la regolamentazione amministrativa (ad esempio, gli standard ISO); o la soft law (ad esempio, i poteri delle autorità di protezione dei dati).


L'obiettivo delle regole secondarie di cambiamento è di permettere la creazione, la modifica e la soppressione delle regole primarie. Questo obiettivo può riguardare la sostituzione di un dato regolamento, ad esempio, le regole primarie della direttiva 46 sulla protezione dei dati dell'UE del 1995, con il nuovo insieme di regole primarie del GDPR, o possono riguardare meccanismi di flessibilità giuridica. 

Consideriamo la politica federale sui veicoli automatizzati adottata dal Dipartimento dei Trasporti degli Stati Uniti nel 2016. Qui possiamo apprezzare l'obiettivo legislativo generale della politica, cioè il principio di "neutralità di implementazione", nel senso che non intende favorire una o più delle possibili applicazioni nel campo delle auto a guida autonoma. Un altro approccio alle sfide dell'innovazione tecnologica è stato elaborato dal governo giapponese attraverso la creazione di zone speciali per la sperimentazione e lo sviluppo empirico della robotica, cioè una forma di laboratorio vivente, o Tokku. Dopo che l'Ufficio di Gabinetto ha approvato la prima zona speciale robotica del mondo che copre la prefettura di Fukuoka e la città di Kitakyushu nel novembre 2003, altre zone speciali sono state stabilite a Osaka e Gifu, Kanagawa e Tsukuba. 


L'obiettivo generale di queste zone speciali è quello di istituire una sorta di interfaccia per i robot e la società, in cui gli scienziati e i profani possono testare se le molteplici applicazioni di Al soddisfano le loro specifiche di compito in modi che sono accettabili e confortevoli per gli esseri umani di fronte all'incertezza della sicurezza della macchina e alle responsabilità legali che riguardano, ad esempio, la protezione per il trattamento dei dati personali. Nel 2008 è stata istituita una zona speciale per la privacy e la protezione dei dati nella città di Kyoto. 

L'interazione tra il diritto e la tecnologia, ad esempio, le regole del GDPR e le sfide dei Big Data, può quindi essere esplorata distinguendo tra le regole primarie e secondarie della legge. Questa differenziazione fa luce sui diversi scopi e modi in cui il comportamento umano e sociale è stato regolato dal GDPR. 

La prossima sezione del documento esamina le regole primarie del GDPR in termini di sfide legali dei Big Data. Poi, nella sezione IV, l'attenzione sarà attirata su quattro diversi tipi di regole secondarie al lavoro con il GDPR (primary rules of gdpr).